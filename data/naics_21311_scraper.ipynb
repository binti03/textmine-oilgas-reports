{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper code to extract reports of NAICS id: 213111, 213112\n",
    "- NAICS 213111 - Drilling Oil and Gas Wells Accidents\n",
    "- NAICS 213112 - Oil and Gas Field Services and Not Elsewhere Classified Accidents\n",
    "- This code downloads the accident reports for 5 years data from 2013 to 2017\n",
    "- The final data will have three fields - the accident date, report id and report text\n",
    "- Each report will be appended to a pandas dataframe and finally exported to a csv file\n",
    "\n",
    "<n/>\n",
    "This code is more concise than the previous *naics_237120_scraper.ipynb* file. It has the same working mechanism with fewer lines of code and little to no explanation as to how it works. But if you follow the previous scraper code this should be no different and easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url to begin crawling\n",
    "home_page_url = \"https://www.osha.gov/pls/imis/AccidentSearch.search?p_logger=1&acc_description=&acc_Abstract=&acc_keyword=&sic=&naics=21311&Office=All&officetype=All&endmonth=01&endday=01&endyear=2001&startmonth=12&startday=31&startyear=2017&InspNr=\"\n",
    "page_url = home_page_url\n",
    "url_header = \"https://www.osha.gov/pls/imis/\"   #to open summary reports and next pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets also create empty lists for all fields\n",
    "event_date = []\n",
    "report_id = []\n",
    "summary = []\n",
    "company = []\n",
    "degree = []\n",
    "age = []\n",
    "nature = []\n",
    "flag = True   # setup a flag to exit loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now iterate the entire scraping process for each page and each row in a page inside a while loop\n",
    "while(flag is True):\n",
    "    response = requests.get(page_url)\n",
    "    page_content = BeautifulSoup(response.content, 'lxml')\n",
    "    \n",
    "    records = (page_content.find(\"div\", id = (\"wrapper\"))\n",
    "               .find(\"div\", id = \"maincontain\", class_ = \"container\")\n",
    "               .find_all(\"table\", class_ = (\"table table-bordered table-striped\"))[1])\n",
    "    rcd_rows = records.find_all('tr')[1:]\n",
    "    for tr in rcd_rows:\n",
    "        td = tr.find_all('td')\n",
    "        row = [i.text for i in td]\n",
    "        event_date.append(row[3])    # copy date into list\n",
    "        report_id.append(row[4])    # copy report_id into list\n",
    "        # navigate to summary url\n",
    "        rpt_url = url_header + str(tr.a.get('href'))\n",
    "        rqst = requests.get(rpt_url)\n",
    "        soup = BeautifulSoup(rqst.content, \"lxml\")\n",
    "        smr = (soup.find(\"div\", id = \"maincontain\", class_ = \"container\")\n",
    "            .find(\"table\", class_ = (\"tablei_100 table-borderedi_100 table-striped\")))\n",
    "        smr_rows = smr.find_all('tr')[1:]\n",
    "        for r in smr_rows:\n",
    "            if r.td:\n",
    "                if r.td.attrs['colspan'] == '8':\n",
    "                    summary.append(r.td.text.strip())\n",
    "                    break\n",
    "        company.append(smr_rows[1].find_all('td')[3].text)\n",
    "        degree.append(smr_rows[-1].find_all('td')[4].text)\n",
    "        age.append(smr_rows[-1].find_all('td')[2].text)\n",
    "        nature.append(smr_rows[-1].find_all('td')[5].text)\n",
    "        \n",
    "    nxt_page = (page_content\n",
    "            .find(\"div\", id = \"maincontain\", class_ = \"container\")\n",
    "            .find_all('div', class_=\"text-right\")[1]\n",
    "            .find('a', title=\"Next Page\"))\n",
    "    if nxt_page != None: \n",
    "        page_url = url_header + str(nxt_page.get('href'))\n",
    "    else:\n",
    "        flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report_ID</th>\n",
       "      <th>Event_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Nature</th>\n",
       "      <th>Establishment</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0627700</td>\n",
       "      <td>12/31/2017</td>\n",
       "      <td>50</td>\n",
       "      <td>Other</td>\n",
       "      <td>Ada Energy Service, Llc</td>\n",
       "      <td>At 9:30 a.m. on December 31, 2017, an employee...</td>\n",
       "      <td>Fatality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0627700</td>\n",
       "      <td>12/30/2017</td>\n",
       "      <td>28</td>\n",
       "      <td>Fracture</td>\n",
       "      <td>H.L. Morris Farms, Inc.</td>\n",
       "      <td>At 11:00 a.m. on December 30, 2017, an employe...</td>\n",
       "      <td>Fatality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0627700</td>\n",
       "      <td>12/21/2017</td>\n",
       "      <td>35</td>\n",
       "      <td>Fracture</td>\n",
       "      <td>Ricks Well Service Llc</td>\n",
       "      <td>At 10:45 a.m. on December 21, 2017, an employe...</td>\n",
       "      <td>Fatality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0950647</td>\n",
       "      <td>12/04/2017</td>\n",
       "      <td>21</td>\n",
       "      <td>Fracture</td>\n",
       "      <td>Applied Technologies Associates</td>\n",
       "      <td>At 11:40 a.m. on December 4, 2017, an employee...</td>\n",
       "      <td>Hospitalized injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0626300</td>\n",
       "      <td>11/28/2017</td>\n",
       "      <td>30</td>\n",
       "      <td>Concussion</td>\n",
       "      <td>Southern Petroleum Laboratories, Inc.</td>\n",
       "      <td>At 12:18 p.m. on November 28, 2017, Employee #...</td>\n",
       "      <td>Hospitalized injury</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Report_ID  Event_Date Age      Nature  \\\n",
       "0   0627700  12/31/2017  50       Other   \n",
       "1   0627700  12/30/2017  28    Fracture   \n",
       "2   0627700  12/21/2017  35    Fracture   \n",
       "3   0950647  12/04/2017  21    Fracture   \n",
       "4   0626300  11/28/2017  30  Concussion   \n",
       "\n",
       "                           Establishment  \\\n",
       "0                Ada Energy Service, Llc   \n",
       "1                H.L. Morris Farms, Inc.   \n",
       "2                 Ricks Well Service Llc   \n",
       "3        Applied Technologies Associates   \n",
       "4  Southern Petroleum Laboratories, Inc.   \n",
       "\n",
       "                                             Summary               Degree  \n",
       "0  At 9:30 a.m. on December 31, 2017, an employee...             Fatality  \n",
       "1  At 11:00 a.m. on December 30, 2017, an employe...             Fatality  \n",
       "2  At 10:45 a.m. on December 21, 2017, an employe...             Fatality  \n",
       "3  At 11:40 a.m. on December 4, 2017, an employee...  Hospitalized injury  \n",
       "4  At 12:18 p.m. on November 28, 2017, Employee #...  Hospitalized injury  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe out of the lists\n",
    "acc_rpts = pd.DataFrame({\"Report_ID\" : report_id,\n",
    "                         \"Event_Date\" : event_date, \n",
    "                         \"Age\" : age,\n",
    "                         \"Nature\" : nature,\n",
    "                         \"Establishment\" : company,\n",
    "                         \"Summary\" : summary,\n",
    "                         \"Degree\" : degree\n",
    "                         })\n",
    "acc_rpts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as csv files\n",
    "acc_rpts.to_csv('naics_21311_data.csv', sep=',', encoding='utf-8', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tm_oil]",
   "language": "python",
   "name": "conda-env-tm_oil-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
