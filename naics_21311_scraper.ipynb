{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper code to extract reports of NAICS id: 213111, 213112\n",
    "- NAICS 213111 - Drilling Oil and Gas Wells Accidents\n",
    "- NAICS 213112 - Oil and Gas Field Services and Not Elsewhere Classified Accidents\n",
    "- This code downloads the accident reports for 5 years data from 2013 to 2017\n",
    "- The final data will have three fields - the accident date, report id and report text\n",
    "- Each report will be appended to a pandas dataframe and finally exported to a csv file\n",
    "\n",
    "<n/>\n",
    "This code is more concise than the previous *naics_237120_scraper.ipynb* file. It has the same working mechanism with fewer lines of code and little to no explanation as to how it works. But if you follow the previous scraper code this should be no different and easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url to begin crawling\n",
    "home_page_url = \"https://www.osha.gov/pls/imis/AccidentSearch.search?p_logger=1&acc_description=&acc_Abstract=&acc_keyword=&sic=&naics=21311&Office=All&officetype=All&endmonth=01&endday=01&endyear=2013&startmonth=12&startday=31&startyear=2017&InspNr=\"\n",
    "page_url = home_page_url\n",
    "url_header = \"https://www.osha.gov/pls/imis/\"   #to open summary reports and next pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets also create empty lists for all fields\n",
    "event_date = []\n",
    "report_id = []\n",
    "summary = []\n",
    "flag = True   # setup a flag to exit loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now iterate the entire scraping process for each page and each row in a page inside a while loop\n",
    "while(flag is True):\n",
    "    response = requests.get(page_url, timeout=5)\n",
    "    page_content = BeautifulSoup(response.content, 'lxml')\n",
    "    \n",
    "    records = (page_content.find(\"div\", id = (\"wrapper\"))\n",
    "               .find(\"div\", id = \"maincontain\", class_ = \"container\")\n",
    "               .find_all(\"table\", class_ = (\"table table-bordered table-striped\"))[1])\n",
    "    rcd_rows = records.find_all('tr')[1:]\n",
    "    for tr in rcd_rows:\n",
    "        td = tr.find_all('td')\n",
    "        row = [i.text for i in td]\n",
    "        event_date.append(row[3])    # copy date into list\n",
    "        report_id.append(row[4])    # copy report_id into list\n",
    "        # navigate to summary url\n",
    "        rpt_url = url_header + str(tr.a.get('href'))\n",
    "        rqst = requests.get(rpt_url, timeout=5)\n",
    "        soup = BeautifulSoup(rqst.content, \"lxml\")\n",
    "        smr = (soup.find(\"div\", id = \"maincontain\", class_ = \"container\")\n",
    "            .find(\"table\", class_ = (\"tablei_100 table-borderedi_100 table-striped\")))\n",
    "        smr_rows = smr.find_all('tr')[1:]\n",
    "        for r in smr_rows:\n",
    "            if r.td:\n",
    "                if r.td.attrs['colspan'] == '8':\n",
    "                    summary.append(r.td.text.strip())\n",
    "                    break\n",
    "                    \n",
    "    nxt_page = (page_content\n",
    "            .find(\"div\", id = \"maincontain\", class_ = \"container\")\n",
    "            .find_all('div', class_=\"text-right\")[1]\n",
    "            .find('a', title=\"Next Page\"))\n",
    "    if nxt_page != None: \n",
    "        page_url = url_header + str(nxt_page.get('href'))\n",
    "    else:\n",
    "        flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_Date</th>\n",
       "      <th>Report_ID</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/31/2017</td>\n",
       "      <td>0627700</td>\n",
       "      <td>At 9:30 a.m. on December 31, 2017, an employee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/30/2017</td>\n",
       "      <td>0627700</td>\n",
       "      <td>At 11:00 a.m. on December 30, 2017, an employe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/21/2017</td>\n",
       "      <td>0627700</td>\n",
       "      <td>At 10:45 a.m. on December 21, 2017, an employe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/28/2017</td>\n",
       "      <td>0626300</td>\n",
       "      <td>At 12:18 p.m. on November 28, 2017, Employee #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/27/2017</td>\n",
       "      <td>0627700</td>\n",
       "      <td>At 3:15 p.m. on November 27, 2017, Employee #1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event_Date Report_ID                                            Summary\n",
       "0  12/31/2017   0627700  At 9:30 a.m. on December 31, 2017, an employee...\n",
       "1  12/30/2017   0627700  At 11:00 a.m. on December 30, 2017, an employe...\n",
       "2  12/21/2017   0627700  At 10:45 a.m. on December 21, 2017, an employe...\n",
       "3  11/28/2017   0626300  At 12:18 p.m. on November 28, 2017, Employee #...\n",
       "4  11/27/2017   0627700  At 3:15 p.m. on November 27, 2017, Employee #1..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe out of the lists\n",
    "acc_rpts = pd.DataFrame({\"Event_Date\" : event_date, \n",
    "                         \"Report_ID\" : report_id, \n",
    "                         \"Summary\" : summary})\n",
    "acc_rpts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as csv files\n",
    "acc_rpts.to_csv('naics_21311_data.csv', sep=',', encoding='utf-8', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tm_oil]",
   "language": "python",
   "name": "conda-env-tm_oil-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
